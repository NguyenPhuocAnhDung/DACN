{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4ef3d3",
   "metadata": {},
   "source": [
    "# IDS Full Benchmark (One Notebook)\n",
    "- **Dataset chính:** CICDDoS2017 + CICDDoS2019 (đọc từng file, liệt kê nhãn), sau đó gộp.\n",
    "- **Pipeline giữ nguyên:** gộp → chuẩn hóa nhãn → **split 8/2** (stratify) → **Scaler + SMOTE** → train → đánh giá.\n",
    "- **Phase‑1 (Binary):** Benign vs DDoS.\n",
    "- **Phase‑2 (Multiclass):** chỉ trên các mẫu DDoS, phân loại loại tấn công (AttackType nhóm lại giống notebook cũ).\n",
    "- **Benchmark:** so sánh nhiều model cho **cả 2 phase** (LightGBM, XGBoost, CatBoost, HistGBDT, RF, ExtraTrees, BalancedRF*, LogReg, LinearSVC-Calib, SVC‑RBF, Ridge, KNN, GaussianNB). (*) BalancedRF cần `imblearn`.\n",
    "- **Tùy chọn:** phần cuối có **NSL-KDD** và **UNSW_NB15** chạy độc lập nếu thư mục có dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b24d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Imports & flags ====\n",
    "import os, time, math, warnings\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score, classification_report,\n",
    "                             confusion_matrix)\n",
    "\n",
    "# Base models\n",
    "LGBM_AVAILABLE = True; XGB_AVAILABLE = True; CAT_AVAILABLE = True\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    LGBM_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "except Exception:\n",
    "    CAT_AVAILABLE = False\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Optional extras\n",
    "BRF_AVAILABLE = True\n",
    "try:\n",
    "    from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "except Exception:\n",
    "    BRF_AVAILABLE = False\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib, pickle, pyarrow\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print({\n",
    "    \"lightgbm\":LGBM_AVAILABLE, \"xgboost\":XGB_AVAILABLE, \"catboost\":CAT_AVAILABLE,\n",
    "    \"BRF\":BRF_AVAILABLE\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b97e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Utils ====\n",
    "def plot_cm(cm, labels, title):\n",
    "    plt.figure(figsize=(max(6, len(labels)*0.6), max(5, len(labels)*0.5)))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ff289",
   "metadata": {},
   "source": [
    "## 1) Load CICDDoS2017 + CICDDoS2019 (main) & liệt kê nhãn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50eedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collect_2019(root=r'dataset/CICDDoS2019'):\n",
    "    train_paths, test_paths, labels = [], [], set()\n",
    "    for dirname,_,files in os.walk(root):\n",
    "        for fn in files:\n",
    "            if fn.endswith('-training.parquet'):\n",
    "                p=os.path.join(dirname,fn); train_paths.append(p); labels.add(fn.split('-')[0])\n",
    "            elif fn.endswith('-testing.parquet'):\n",
    "                p=os.path.join(dirname,fn); test_paths.append(p); labels.add(fn.split('-')[0])\n",
    "    return train_paths, test_paths, sorted(labels)\n",
    "\n",
    "def collect_2017(root=r'dataset/CICDDoS2017'):\n",
    "    paths, labels = [], set()\n",
    "    for dirname,_,files in os.walk(root):\n",
    "        for fn in files:\n",
    "            if fn.endswith('.parquet'):\n",
    "                p=os.path.join(dirname,fn); paths.append(p); labels.add(fn.split('-')[0])\n",
    "    return paths, sorted(labels)\n",
    "\n",
    "p2019_train, p2019_test, labels2019 = collect_2019()\n",
    "p2017, labels2017 = collect_2017()\n",
    "print(\"2019 train files:\", len(p2019_train), \"| 2017 files:\", len(p2017))\n",
    "\n",
    "print(\"\\nCác nhãn (2019) ví dụ:\")\n",
    "for lb in labels2019[:20]: print(\"-\", lb)\n",
    "print(\"\\nCác nhãn (2017) ví dụ:\")\n",
    "for lb in labels2017[:20]: print(\"-\", lb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956bcc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Đọc & gộp 2017 + 2019 ====\n",
    "df_2017 = pd.concat([pd.read_parquet(p) for p in p2017], ignore_index=True) if len(p2017) else pd.DataFrame()\n",
    "df_2019 = pd.concat([pd.read_parquet(p) for p in p2019_train], ignore_index=True) if len(p2019_train) else pd.DataFrame()\n",
    "assert len(df_2017) or len(df_2019), \"Không có dữ liệu 2017/2019 để gộp.\"\n",
    "\n",
    "df = pd.concat([df_2017, df_2019], ignore_index=True)\n",
    "df['AttackType'] = df['Label']\n",
    "df['Label'] = df['Label'].apply(lambda s: 'Benign' if s=='Benign' else 'DDoS')\n",
    "print(df.shape, df['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c571dd",
   "metadata": {},
   "source": [
    "## 2) Danh sách đặc trưng (giữ nguyên form) + split 8/2 + Scaler + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ff8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_names = [\n",
    "    'Protocol', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',\n",
    "    'Fwd Packets Length Total', 'Bwd Packets Length Total', 'Fwd Packet Length Max',\n",
    "    'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std',\n",
    "    'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
    "    'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean',\n",
    "    'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean',\n",
    "    'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
    "    'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags',\n",
    "    'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length',\n",
    "    'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max',\n",
    "    'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count',\n",
    "    'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count',\n",
    "    'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Avg Packet Size',\n",
    "    'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk',\n",
    "    'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate',\n",
    "    'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes',\n",
    "    'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Act Data Packets', 'Fwd Seg Size Min',\n",
    "    'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std',\n",
    "    'Idle Max', 'Idle Min'\n",
    "]\n",
    "\n",
    "df = df.fillna(0)\n",
    "X = df[features_names].astype(np.float32).values\n",
    "y_bin = (df['Label']!='Benign').astype(int).values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y_bin, test_size=0.2, random_state=42, stratify=y_bin)\n",
    "scaler = MinMaxScaler().fit(X_tr)\n",
    "X_tr_s = scaler.transform(X_tr); X_te_s = scaler.transform(X_te)\n",
    "\n",
    "# SMOTE trên train (giữ nguyên tinh thần notebook cũ)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_tr, y_tr)\n",
    "X_res_s = scaler.transform(X_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4076f6",
   "metadata": {},
   "source": [
    "## 3) Phase‑1 (Binary) — Model zoo & Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a392451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_zoo_binary():\n",
    "    models = {}\n",
    "    if LGBM_AVAILABLE:\n",
    "        models[\"LightGBM\"] = lgb.LGBMClassifier(n_estimators=800, learning_rate=0.07, max_depth=8,\n",
    "                                                num_leaves=256, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                class_weight=\"balanced\", n_jobs=-1, random_state=42)\n",
    "    if XGB_AVAILABLE:\n",
    "        models[\"XGBoost\"] = xgb.XGBClassifier(n_estimators=800, learning_rate=0.06, max_depth=8,\n",
    "                                              subsample=0.8, colsample_bytree=0.8, reg_lambda=2.0,\n",
    "                                              tree_method=\"hist\", n_jobs=-1, eval_metric=\"logloss\", random_state=42)\n",
    "    if CAT_AVAILABLE:\n",
    "        models[\"CatBoost\"] = CatBoostClassifier(iterations=1000, learning_rate=0.07, depth=8,\n",
    "                                                l2_leaf_reg=5.0, loss_function=\"Logloss\",\n",
    "                                                auto_class_weights=\"Balanced\", verbose=False, random_seed=42)\n",
    "    models[\"HistGBDT\"] = HistGradientBoostingClassifier(max_depth=None, learning_rate=0.08, max_iter=600)\n",
    "    models[\"RandomForest\"] = RandomForestClassifier(n_estimators=600, n_jobs=-1, class_weight=\"balanced_subsample\", random_state=42)\n",
    "    models[\"ExtraTrees\"] = ExtraTreesClassifier(n_estimators=700, n_jobs=-1, random_state=42)\n",
    "    if BRF_AVAILABLE:\n",
    "        models[\"BalancedRF\"] = BalancedRandomForestClassifier(n_estimators=600, random_state=42, n_jobs=-1)\n",
    "    models[\"LogReg\"] = LogisticRegression(max_iter=1200, n_jobs=-1)\n",
    "    models[\"LinearSVC-Calib\"] = CalibratedClassifierCV(LinearSVC(), cv=3)\n",
    "    models[\"SVC-RBF\"] = SVC(kernel='rbf', C=2.0, gamma='scale')\n",
    "    models[\"RidgeCls\"] = RidgeClassifier()\n",
    "    models[\"KNN-11\"] = KNeighborsClassifier(n_neighbors=11)\n",
    "    models[\"GaussianNB\"] = GaussianNB()\n",
    "    return models\n",
    "\n",
    "def run_benchmark_binary(models: dict, Xtr, ytr, Xte, yte):\n",
    "    rows = []\n",
    "    for name, mdl in models.items():\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            mdl.fit(Xtr, ytr)\n",
    "            train_s = f\\\"{time.time()-t0:.1f}s\\\"\n",
    "            try:\n",
    "                yhat = mdl.predict(Xte)\n",
    "            except Exception:\n",
    "                yhat = (mdl.predict_proba(Xte)[:,1]>0.5).astype(int)\n",
    "            acc = accuracy_score(yte, yhat)\n",
    "            f1m = f1_score(yte, yhat, average='macro')\n",
    "            f1w = f1_score(yte, yhat, average='weighted')\n",
    "            try:\n",
    "                proba = mdl.predict_proba(Xte)[:,1]; auc = roc_auc_score(yte, proba)\n",
    "            except Exception:\n",
    "                try:\n",
    "                    proba = mdl.decision_function(Xte); auc = roc_auc_score(yte, proba)\n",
    "                except Exception:\n",
    "                    auc = np.nan\n",
    "            rows.append([name, acc, f1m, f1w, auc, train_s])\n",
    "            print(f\\\"{name:16s} | acc={acc:.4f} f1m={f1m:.4f} f1w={f1w:.4f} auc={auc if not math.isnan(auc) else np.nan} time={train_s}\\\")\n",
    "        except Exception as e:\n",
    "            print(f\\\"[SKIP] {name}: {e}\\\")\n",
    "    cols = [\\\"model\\\",\\\"accuracy\\\",\\\"f1_macro\\\",\\\"f1_weighted\\\",\\\"roc_auc\\\",\\\"train_time\\\"]\n",
    "    return pd.DataFrame(rows, columns=cols).sort_values(\\\"f1_macro\\\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "models_bin = model_zoo_binary()\n",
    "res_bin = run_benchmark_binary(models_bin, X_res_s, y_res, X_te_s, y_te)\n",
    "res_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb38572",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot & export (Phase‑1)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=res_bin, x=\"model\", y=\"f1_macro\")\n",
    "plt.xticks(rotation=45, ha='right'); plt.title(\"Binary F1-macro (Benign vs DDoS)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "res_bin.to_csv(\"benchmark_binary_results.csv\", index=False)\n",
    "res_bin.to_excel(\"benchmark_binary_results.xlsx\", index=False)\n",
    "res_bin.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532a90e",
   "metadata": {},
   "source": [
    "## 4) Phase‑2 (Multiclass trên DDoS) — Model zoo & Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8342e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gom nhóm AttackType như notebook cũ\n",
    "attack_group_map = {\n",
    "    'DrDoS_DNS': 'DrDoS','DrDoS_SNMP': 'DrDoS','DrDoS_NTP': 'DrDoS','DrDoS_MSSQL': 'DrDoS',\n",
    "    'DrDoS_SSDP': 'DrDoS','DrDoS_UDP': 'DrDoS','TFTP': 'TFTP','UDP': 'UDP','UDPLag': 'UDP',\n",
    "    'Syn': 'Syn','MSSQL': 'MSSQL','LDAP': 'LDAP','DoS slowloris': 'DoS','DoS Slowhttptest': 'DoS',\n",
    "    'DoS Hulk': 'DoS','DoS GoldenEye': 'DoS','Heartbleed': 'Other','Web Attack � Brute Force': 'Web Attack',\n",
    "    'Web Attack � XSS': 'Web Attack','Web Attack � Sql Injection': 'Web Attack','FTP-Patator': 'Brute Force',\n",
    "    'SSH-Patator': 'Brute Force','Infiltration': 'Other','Bot': 'Other','PortScan': 'PortScan','NetBIOS': 'Other',\n",
    "}\n",
    "def group_attack(x): \n",
    "    return 'Benign' if x=='Benign' else attack_group_map.get(x,'Other')\n",
    "\n",
    "df['AttackType'] = df['AttackType'].apply(group_attack)\n",
    "\n",
    "# Lấy riêng DDoS\n",
    "ddos = df[df['Label']=='DDoS'].copy()\n",
    "Xa = ddos[features_names].astype(np.float32).values\n",
    "ya = ddos['AttackType'].astype(str).values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder(); ya_enc = le.fit_transform(ya)\n",
    "n_classes = len(le.classes_)\n",
    "print(\"Classes:\", list(le.classes_))\n",
    "\n",
    "Xa_tr, Xa_te, ya_tr, ya_te = train_test_split(Xa, ya_enc, test_size=0.2, random_state=42, stratify=ya_enc)\n",
    "scaler_a = MinMaxScaler().fit(Xa_tr)\n",
    "Xa_tr_s = scaler_a.transform(Xa_tr); Xa_te_s = scaler_a.transform(Xa_te)\n",
    "\n",
    "sm2 = SMOTE(random_state=42)\n",
    "Xa_res, ya_res = sm2.fit_resample(Xa_tr, ya_tr)\n",
    "Xa_res_s = scaler_a.transform(Xa_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def model_zoo_multi(nc:int):\n",
    "    models = {}\n",
    "    if LGBM_AVAILABLE:\n",
    "        models[\"LightGBM\"] = lgb.LGBMClassifier(n_estimators=1000, learning_rate=0.05, max_depth=9,\n",
    "                                                num_leaves=256, subsample=0.9, colsample_bytree=0.9,\n",
    "                                                class_weight=\"balanced\", n_jobs=-1, random_state=42)\n",
    "    if XGB_AVAILABLE:\n",
    "        models[\"XGBoost\"] = xgb.XGBClassifier(n_estimators=1000, learning_rate=0.05, max_depth=9,\n",
    "                                              subsample=0.9, colsample_bytree=0.9, reg_lambda=2.0,\n",
    "                                              tree_method=\"hist\", n_jobs=-1, objective=\"multi:softprob\",\n",
    "                                              num_class=nc, random_state=42)\n",
    "    if CAT_AVAILABLE:\n",
    "        models[\"CatBoost\"] = CatBoostClassifier(iterations=1200, learning_rate=0.05, depth=8, l2_leaf_reg=5.0,\n",
    "                                                loss_function=\"MultiClass\", auto_class_weights=\"Balanced\",\n",
    "                                                verbose=False, random_seed=42)\n",
    "    models[\"HistGBDT\"] = HistGradientBoostingClassifier(max_iter=900)\n",
    "    models[\"ExtraTrees\"] = ExtraTreesClassifier(n_estimators=800, n_jobs=-1, random_state=42)\n",
    "    models[\"RandomForest\"] = RandomForestClassifier(n_estimators=700, n_jobs=-1, random_state=42)\n",
    "    models[\"LogReg-OvR\"] = OneVsRestClassifier(LogisticRegression(max_iter=1500, n_jobs=-1))\n",
    "    models[\"LinearSVC-OvR\"] = OneVsRestClassifier(LinearSVC())\n",
    "    models[\"KNN-11\"] = KNeighborsClassifier(n_neighbors=11)\n",
    "    return models\n",
    "\n",
    "def run_benchmark_multi(models: dict, Xtr, ytr, Xte, yte):\n",
    "    rows = []\n",
    "    for name, mdl in models.items():\n",
    "        t0=time.time()\n",
    "        try:\n",
    "            mdl.fit(Xtr, ytr)\n",
    "            tr=f\\\"{time.time()-t0:.1f}s\\\"\n",
    "            yhat = mdl.predict(Xte)\n",
    "            acc=accuracy_score(yte,yhat); f1m=f1_score(yte,yhat,average='macro'); f1w=f1_score(yte,yhat,average='weighted')\n",
    "            rows.append([name,acc,f1m,f1w,tr])\n",
    "            print(f\\\"{name:16s} | acc={acc:.4f} f1m={f1m:.4f} f1w={f1w:.4f} time={tr}\\\")\n",
    "        except Exception as e:\n",
    "            print(f\\\"[SKIP] {name}: {e}\\\")\n",
    "    return pd.DataFrame(rows, columns=[\\\"model\\\",\\\"accuracy\\\",\\\"f1_macro\\\",\\\"f1_weighted\\\",\\\"train_time\\\"]).sort_values(\\\"f1_macro\\\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "models_multi = model_zoo_multi(n_classes)\n",
    "res_multi = run_benchmark_multi(models_multi, Xa_res_s, ya_res, Xa_te_s, ya_te)\n",
    "res_multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot & export (Phase‑2)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=res_multi, x=\"model\", y=\"f1_macro\")\n",
    "plt.xticks(rotation=45, ha='right'); plt.title(\"Multiclass F1-macro (DDoS Attack Types)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "res_multi.to_csv(\"benchmark_multiclass_results.csv\", index=False)\n",
    "res_multi.to_excel(\"benchmark_multiclass_results.xlsx\", index=False)\n",
    "res_multi.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bcd300",
   "metadata": {},
   "source": [
    "## 5) Tuỳ chọn: NSL‑KDD & UNSW_NB15 (độc lập, cùng pipeline 8/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_folder_any(root):\n",
    "    paths=[]\n",
    "    for dirname,_,files in os.walk(root):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith(('.csv','.txt','.parquet')):\n",
    "                paths.append(os.path.join(dirname, fn))\n",
    "    return paths\n",
    "\n",
    "def generic_binary_eval(paths, dataset_name):\n",
    "    if not paths:\n",
    "        print(f\"[{dataset_name}] Không tìm thấy file -> bỏ qua.\"); return None\n",
    "    frames=[]\n",
    "    for p in paths:\n",
    "        try:\n",
    "            if p.endswith('.parquet'):\n",
    "                frames.append(pd.read_parquet(p))\n",
    "            else:\n",
    "                try:\n",
    "                    frames.append(pd.read_csv(p))\n",
    "                except Exception:\n",
    "                    frames.append(pd.read_csv(p, sep='\\\\s+', header=None))\n",
    "        except Exception as e:\n",
    "            print(\"Skip\", p, e)\n",
    "    if not frames: \n",
    "        print(f\"[{dataset_name}] Không đọc được bảng hợp lệ.\"); return None\n",
    "    df = pd.concat(frames, ignore_index=True).fillna(0)\n",
    "    # suy đoán cột nhãn\n",
    "    label_col=None\n",
    "    for c in ['label','Label','attack','attack_cat','class','Class','target']:\n",
    "        if c in df.columns: label_col=c; break\n",
    "    if label_col is None: label_col = df.columns[-1]\n",
    "    X = df.select_dtypes(include=[np.number]).values\n",
    "    y_raw = df[label_col].astype(str).values\n",
    "    y = np.array([0 if s.lower() in ['benign','normal','0'] else 1 for s in y_raw])\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    scaler = MinMaxScaler().fit(X_tr)\n",
    "    X_tr_s = scaler.transform(X_tr); X_te_s = scaler.transform(X_te)\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_resample(X_tr_s, y_tr)\n",
    "\n",
    "    models = model_zoo_binary()\n",
    "    res = run_benchmark_binary(models, X_res, y_res, X_te_s, y_te)\n",
    "    res.to_csv(f\"{dataset_name}_binary_results.csv\", index=False)\n",
    "    print(f\"[{dataset_name}] Done.\")\n",
    "    return res\n",
    "\n",
    "# NSL-KDD\n",
    "paths_kdd = read_folder_any(r\"dataset/NSL-KDD\")\n",
    "res_kdd = generic_binary_eval(paths_kdd, \"NSL_KDD\")\n",
    "\n",
    "# UNSW\n",
    "paths_unsw = read_folder_any(r\"dataset/UNSW_NB15\")\n",
    "res_unsw = generic_binary_eval(paths_unsw, \"UNSW_NB15\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
