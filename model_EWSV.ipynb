{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b61a24",
   "metadata": {},
   "source": [
    "\n",
    "# **Imports & cấu hình chung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18057ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # IDS Notebook — Pipeline 2-Phase + Save/Plot + Resume\n",
    "# - Lưu mô hình dạng `.h5` vào D:\\DACN\\results\\training\\models\n",
    "# - Ảnh biểu đồ vào D:\\DACN\\results\\training\\plots\n",
    "# - Bảng so sánh vào D:\\DACN\\results\\training\\tables\n",
    "# - Có thể **tiếp tục train** (resume) mà **không phải chạy lại** tiền xử lý.\n",
    "\n",
    "import os, glob, io, time, json, warnings, joblib, random, pickle, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    precision_recall_fscore_support, accuracy_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==== PATHS (chỉnh theo máy bạn) ====\n",
    "CIC2019_DIR = r'E:\\DACN\\dataset\\CICDDoS2019'\n",
    "CIC2017_DIR = r'E:\\DACN\\dataset\\CICDDoS2017'\n",
    "UNSW15_DIR  = r'E:\\DACN\\dataset\\UNSW_NB15'\n",
    "NSLKDD_DIR  = r'E:\\DACN\\dataset\\NSL-KDD'   # có KDDTrain+.txt, KDDTest+.txt\n",
    "\n",
    "# ==== nơi lưu kết quả ====\n",
    "ROOT_SAVE = Path(r\"E:\\DACN\\results\\training\")\n",
    "DIR_MODELS = ROOT_SAVE / \"models\"\n",
    "DIR_PLOTS  = ROOT_SAVE / \"plots\"\n",
    "DIR_TABLES = ROOT_SAVE / \"tables\"\n",
    "for p in [DIR_MODELS, DIR_PLOTS, DIR_TABLES]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==== loại cột ID/time ====\n",
    "EXCLUDE_ID_COLUMNS = True\n",
    "ID_LIKE_COLS = set([\n",
    "    'Flow ID','FlowID','Timestamp','StartTime','Start Time','stime','time','Date','datetime',\n",
    "    'Src IP','Dst IP','Source IP','Destination IP',\n",
    "    'srcip','dstip','srcip_addr','dstip_addr', \n",
    "    'Src Port','Dst Port','Sport','Dport','srcport','dstport',\n",
    "    'ProtocolName','ProtoName','Service','service','state','attack_cat','label',\n",
    "    'Unnamed: 0','id','No.','Index'\n",
    "])\n",
    "LABEL_CANDS = [\"Label\",\"label\",\"Attack\",\"attack\",\"attack_cat\",\"class\",\"Class\",\"target\",\"category\",\"Category\",\"result\"]\n",
    "\n",
    "# kiểm soát lệch phân bố từ UNSW (toàn attack)\n",
    "MAX_UNSW_RATIO = 0.30   # tối đa 30%\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d557bf",
   "metadata": {},
   "source": [
    "\n",
    "# **Giới hạn CPU + TensorFlow threads**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4189767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CPU] total=28 | allow=25 threads (~90%)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import multiprocessing as mp\n",
    "\n",
    "def limit_cpu(fraction: float = 0.90) -> int:\n",
    "    \"\"\"\n",
    "    Giới hạn tài nguyên CPU ~fraction (theo số luồng).\n",
    "    Trả về số threads cho n_jobs/num_threads.\n",
    "    \"\"\"\n",
    "    fraction = max(0.1, min(1.0, float(fraction)))\n",
    "    total = os.cpu_count() or mp.cpu_count() or 1\n",
    "    allow = max(1, math.floor(total * fraction))\n",
    "\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = str(allow)\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = str(allow)\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = str(allow)\n",
    "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(allow)\n",
    "    os.environ[\"NUMEXPR_MAX_THREADS\"] = str(allow)\n",
    "    os.environ[\"NUMEXPR_NUM_THREADS\"] = str(allow)\n",
    "\n",
    "    try:\n",
    "        from threadpoolctl import threadpool_limits\n",
    "        threadpool_limits(allow)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        import psutil\n",
    "        p = psutil.Process()\n",
    "        cpus = list(range(allow))\n",
    "        p.cpu_affinity(cpus)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    print(f\"[CPU] total={total} | allow={allow} threads (~{fraction*100:.0f}%)\")\n",
    "    return allow\n",
    "\n",
    "threads_allowed = limit_cpu(0.90)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.threading.set_intra_op_parallelism_threads(threads_allowed)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(max(1, threads_allowed//2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1734c362",
   "metadata": {},
   "source": [
    "\n",
    "# **Hàm I/O an toàn + Chuẩn hoá nhãn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3749d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read_any(path: str, nrows=None) -> pd.DataFrame:\n",
    "    low = path.lower()\n",
    "    try:\n",
    "        if low.endswith(\".parquet\"):\n",
    "            return pd.read_parquet(path) if nrows is None else pd.read_parquet(path).head(nrows)\n",
    "        # NSL-KDD .txt không header\n",
    "        if low.endswith(\".txt\") and (\"kddtrain\" in low or \"kddtest\" in low):\n",
    "            df = pd.read_csv(path, header=None)\n",
    "            if df.shape[1] == 43:\n",
    "                cols = [f\"feat_{i}\" for i in range(41)] + [\"label\",\"difficulty\"]\n",
    "            elif df.shape[1] == 42:\n",
    "                cols = [f\"feat_{i}\" for i in range(41)] + [\"label\"]\n",
    "            else:\n",
    "                cols = [f\"col_{i}\" for i in range(df.shape[1])]\n",
    "            df.columns = cols\n",
    "            return df if nrows is None else df.head(nrows)\n",
    "        # CSV chung\n",
    "        for enc in (\"utf-8-sig\",\"utf-8\",\"cp1252\",\"latin1\"):\n",
    "            try:\n",
    "                return pd.read_csv(path, encoding=enc, compression=\"infer\", low_memory=False, nrows=nrows)\n",
    "            except Exception:\n",
    "                continue\n",
    "        return pd.read_csv(path, compression=\"infer\", low_memory=False, nrows=nrows)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] skip {os.path.basename(path)}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def find_label_col(df: pd.DataFrame):\n",
    "    for c in LABEL_CANDS:\n",
    "        if c in df.columns: return c\n",
    "    return None\n",
    "\n",
    "attack_group_map = {\n",
    "    'DrDoS_DNS':'DrDoS','DrDoS_SNMP':'DrDoS','DrDoS_NTP':'DrDoS','DrDoS_MSSQL':'DrDoS',\n",
    "    'DrDoS_SSDP':'DrDoS','DrDoS_UDP':'DrDoS','TFTP':'TFTP',\n",
    "    'UDP':'UDP','UDPLag':'UDP','Syn':'Syn','MSSQL':'MSSQL','LDAP':'LDAP',\n",
    "    'DoS slowloris':'DoS','DoS Slowhttptest':'DoS','DoS Hulk':'DoS','DoS GoldenEye':'DoS',\n",
    "    'Heartbleed':'Other',\n",
    "    'Web Attack � Brute Force':'Web Attack','Web Attack � XSS':'Web Attack','Web Attack � Sql Injection':'Web Attack',\n",
    "    'FTP-Patator':'Brute Force','SSH-Patator':'Brute Force','Infiltration':'Other','Bot':'Other',\n",
    "    'PortScan':'PortScan','NetBIOS':'Other'\n",
    "}\n",
    "\n",
    "def normalize_labels(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    lbl = find_label_col(df)\n",
    "    if lbl is None:\n",
    "        return pd.DataFrame()\n",
    "    df.rename(columns={lbl: \"Label\"}, inplace=True)\n",
    "    df[\"Label\"] = df[\"Label\"].astype(str).str.strip()\n",
    "    df.loc[df[\"Label\"].str.lower().isin([\"normal\",\"benign\",\"non-attack\",\"good\"]), \"Label\"] = \"Benign\"\n",
    "    if \"AttackType\" not in df.columns:\n",
    "        df[\"AttackType\"] = df[\"Label\"]\n",
    "    def group_attack_type(x):\n",
    "        if pd.isna(x): return 'Other'\n",
    "        if x == 'Benign': return 'Benign'\n",
    "        return attack_group_map.get(str(x), 'Other')\n",
    "    df[\"AttackType\"] = df[\"AttackType\"].apply(group_attack_type)\n",
    "    df[\"Label\"] = df[\"Label\"].apply(lambda v: 'Benign' if str(v)=='Benign' else 'DDoS')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0b4acd",
   "metadata": {},
   "source": [
    "\n",
    "# **Liệt kê file & union features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471d6fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIC19 train: 7 CIC19 test: 10\n",
      "CIC17: 8 UNSW: 6 NSL: 4\n",
      "Tổng số cột numeric union: 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['E:\\\\DACN\\\\results\\\\training\\\\feature_order_union.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIC-2019 train/test\n",
    "cic19_train, cic19_test = [], []\n",
    "for root,_,files in os.walk(CIC2019_DIR):\n",
    "    for fn in files:\n",
    "        if fn.endswith(\"-training.parquet\"): cic19_train.append(os.path.join(root, fn))\n",
    "        if fn.endswith(\"-testing.parquet\"):  cic19_test.append(os.path.join(root, fn))\n",
    "\n",
    "# CIC-2017 parquet\n",
    "cic17_files = glob.glob(os.path.join(CIC2017_DIR, \"**\", \"*.parquet\"), recursive=True)\n",
    "\n",
    "# UNSW: bỏ *_features.csv, *_LIST_EVENTS.csv, *_GT.csv\n",
    "unsw_all = glob.glob(os.path.join(UNSW15_DIR, \"**\", \"*.csv\"), recursive=True)\n",
    "unsw_files = [p for p in unsw_all if (\"features\" not in os.path.basename(p).lower()\n",
    "                                      and \"list_events\" not in os.path.basename(p).lower()\n",
    "                                      and not os.path.basename(p).lower().endswith(\"_gt.csv\"))]\n",
    "\n",
    "# NSL: chỉ .txt\n",
    "nsl_all = glob.glob(os.path.join(NSLKDD_DIR, \"**\", \"*.txt\"), recursive=True)\n",
    "nsl_files = [p for p in nsl_all if (\"kddtrain\" in os.path.basename(p).lower() or\n",
    "                                    \"kddtest\" in os.path.basename(p).lower())]\n",
    "\n",
    "print(\"CIC19 train:\", len(cic19_train), \"CIC19 test:\", len(cic19_test))\n",
    "print(\"CIC17:\", len(cic17_files), \"UNSW:\", len(unsw_files), \"NSL:\", len(nsl_files))\n",
    "\n",
    "def infer_numeric_cols(files: List[str]) -> set:\n",
    "    s = set()\n",
    "    for p in files[:10]:\n",
    "        head = safe_read_any(p, nrows=200)\n",
    "        if head.empty: continue\n",
    "        head = normalize_labels(head)\n",
    "        if head.empty: continue\n",
    "        cols = [c for c in head.columns if c not in ID_LIKE_COLS and c not in (\"Label\",\"AttackType\")]\n",
    "        for c in cols:\n",
    "            if pd.api.types.is_numeric_dtype(head[c]):\n",
    "                s.add(c)\n",
    "    s.add(\"dataset_id\")\n",
    "    return s\n",
    "\n",
    "union_cols = set()\n",
    "union_cols |= infer_numeric_cols(cic19_train + cic19_test)\n",
    "union_cols |= infer_numeric_cols(cic17_files)\n",
    "union_cols |= infer_numeric_cols(unsw_files)\n",
    "union_cols |= infer_numeric_cols(nsl_files)\n",
    "\n",
    "FEATURES = sorted(list(union_cols))\n",
    "print(\"Tổng số cột numeric union:\", len(FEATURES))\n",
    "joblib.dump({\"feature_order\": FEATURES}, ROOT_SAVE / \"feature_order_union.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06df568",
   "metadata": {},
   "source": [
    "\n",
    "# **Load & Normalize datasets + Gộp + Lưu parquet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947f0b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load ds1: 100%|██████████| 8/8 [00:01<00:00,  4.18it/s]\n",
      "Load ds2: 100%|██████████| 7/7 [00:00<00:00, 41.07it/s]\n",
      "Load ds2: 100%|██████████| 10/10 [00:00<00:00, 28.14it/s]\n",
      "Load ds3: 100%|██████████| 6/6 [00:09<00:00,  1.51s/it]\n",
      "Load ds4: 100%|██████████| 4/4 [00:00<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: {'CIC17': (2313810, 80), 'CIC19_train': (125170, 80), 'UNSW': (257673, 47), 'NSL': (185559, 45)}\n",
      "Đã lưu: E:\\DACN\\results\\training\\df_all_union.parquet\n"
     ]
    }
   ],
   "source": [
    "def load_and_normalize(files: List[str], dataset_id: int) -> pd.DataFrame:\n",
    "    out = []\n",
    "    for p in tqdm(files, desc=f\"Load ds{dataset_id}\"):\n",
    "        df = safe_read_any(p)\n",
    "        if df.empty: \n",
    "            continue\n",
    "        df = normalize_labels(df)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        df[\"dataset_id\"] = dataset_id\n",
    "        out.append(df)\n",
    "    return pd.concat(out, ignore_index=True) if out else pd.DataFrame()\n",
    "\n",
    "df17  = load_and_normalize(cic17_files, 1)\n",
    "df19t = load_and_normalize(cic19_train, 2)\n",
    "df19e = load_and_normalize(cic19_test, 2)\n",
    "dfUN  = load_and_normalize(unsw_files, 3)\n",
    "dfNSL = load_and_normalize(nsl_files, 4)\n",
    "\n",
    "print(\"Shapes:\", {k:v.shape for k,v in {\"CIC17\":df17,\"CIC19_train\":df19t,\"UNSW\":dfUN,\"NSL\":dfNSL}.items()})\n",
    "\n",
    "# gộp chính (2017 + 2019 train)\n",
    "df_main = pd.concat([df17, df19t], ignore_index=True)\n",
    "\n",
    "# hạn chế UNSW (gần như toàn attack)\n",
    "if not dfUN.empty:\n",
    "    cur_ddos = (df_main[\"Label\"]==\"DDoS\").sum()\n",
    "    cap = int(MAX_UNSW_RATIO * max(1, cur_ddos))\n",
    "    dfUN_ddos = dfUN[dfUN[\"Label\"]==\"DDoS\"]\n",
    "    if len(dfUN_ddos) > cap:\n",
    "        dfUN_ddos = dfUN_ddos.sample(cap, random_state=RANDOM_STATE)\n",
    "    dfUN = dfUN_ddos\n",
    "\n",
    "df_all = pd.concat([df_main, dfUN, dfNSL], ignore_index=True)\n",
    "assert not df_all.empty, \"Không có dữ liệu!\"\n",
    "\n",
    "df_all = df_all.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "for c in df_all.columns:\n",
    "    if df_all[c].dtype == \"object\":\n",
    "        df_all[c] = df_all[c].astype(str)\n",
    "\n",
    "parq_path = ROOT_SAVE / \"df_all_union.parquet\"\n",
    "df_all.to_parquet(parq_path, index=False)\n",
    "print(\"Đã lưu:\", parq_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692909f7",
   "metadata": {},
   "source": [
    "\n",
    "# **Đọc lại parquet + Tạo tập train/test + SMOTE + Chuẩn bị DL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43a354e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đọc lại: (2749109, 166)\n",
      "Số cột dùng: 156\n",
      "Train: (2199287, 156) Test: (549822, 156)\n",
      "After SMOTE: (3386240, 156) | pos_ratio: 0.5\n",
      "DL shapes: (3386240, 156, 1) (549822, 156, 1)\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.read_parquet(ROOT_SAVE / \"df_all_union.parquet\")\n",
    "print(\"Đọc lại:\", df_all.shape)\n",
    "\n",
    "drop_cols = {'Label','AttackType'}\n",
    "if EXCLUDE_ID_COLUMNS:\n",
    "    drop_cols |= {c for c in df_all.columns if c in ID_LIKE_COLS}\n",
    "feature_candidates = [c for c in FEATURES if c not in drop_cols and c in df_all.columns]\n",
    "print(\"Số cột dùng:\", len(feature_candidates))\n",
    "\n",
    "X = df_all.reindex(columns=feature_candidates, fill_value=0.0).astype(np.float32)\n",
    "y_bin = (df_all['Label'] != 'Benign').astype(int).values\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y_bin, test_size=0.2, random_state=RANDOM_STATE, stratify=y_bin\n",
    ")\n",
    "print(\"Train:\", X_train_raw.shape, \"Test:\", X_test_raw.shape)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_raw.values)\n",
    "joblib.dump(scaler, ROOT_SAVE / 'scaler_union.pkl')\n",
    "\n",
    "X_train_s = scaler.transform(X_train_raw.values)\n",
    "X_test_s  = scaler.transform(X_test_raw.values)\n",
    "\n",
    "sm = SMOTE(random_state=RANDOM_STATE)\n",
    "X_res, y_res = sm.fit_resample(X_train_s, y_train)\n",
    "print(\"After SMOTE:\", X_res.shape, \"| pos_ratio:\", y_res.mean().round(4))\n",
    "\n",
    "# Dữ liệu cho DL (mỗi feature là 1 “time step”)\n",
    "X_train_dl = X_res.astype(np.float32).reshape(-1, X_res.shape[1], 1)\n",
    "X_test_dl  = X_test_s.astype(np.float32).reshape(-1, X_test_s.shape[1], 1)\n",
    "y_train_dl = y_res.astype(np.int32)\n",
    "y_test_dl  = y_test.astype(np.int32)\n",
    "\n",
    "print(\"DL shapes:\", X_train_dl.shape, X_test_dl.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d36b79f",
   "metadata": {},
   "source": [
    "\n",
    "# **Tiện ích Save/Load .h5 + Plot (CM + Val)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec3b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def _stamp():\n",
    "    return time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def save_fig_current(fig, name: str):\n",
    "    png = DIR_PLOTS / f\"{name}-{_stamp()}.png\"\n",
    "    fig.savefig(png, dpi=150, bbox_inches=\"tight\")\n",
    "    print(f\"[SAVE] Figure -> {png}\")\n",
    "    return str(png)\n",
    "\n",
    "def save_model_h5_any(model, name: str, extra: dict | None = None):\n",
    "    \"\"\"\n",
    "    Lưu mô hình dạng .h5:\n",
    "    - Keras: model.save(.h5)\n",
    "    - Sklearn/XGBoost/LightGBM: pickle vào HDF5['pickle'] + attrs['extra_json']\n",
    "    \"\"\"\n",
    "    path = DIR_MODELS / f\"{name}-{_stamp()}.h5\"\n",
    "    # Thử Keras trước\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        if hasattr(model, \"save\") and isinstance(getattr(model, \"save\"), type(tf.keras.Model.save)):\n",
    "            model.save(path)\n",
    "            print(f\"[SAVE] Keras model -> {path}\")\n",
    "            if extra:\n",
    "                with open(str(path).replace(\".h5\", \".meta.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(extra, f, ensure_ascii=False, indent=2, default=str)\n",
    "            return str(path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Non-Keras\n",
    "    blob = pickle.dumps(model, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with h5py.File(path, \"w\") as h5:\n",
    "        h5.create_dataset(\"pickle\", data=np.void(blob))\n",
    "        if extra:\n",
    "            try:\n",
    "                h5.attrs[\"extra_json\"] = json.dumps(extra, default=str)\n",
    "            except Exception:\n",
    "                h5.attrs[\"extra_json\"] = \"{}\"\n",
    "    print(f\"[SAVE] Pickled model-in-HDF5 -> {path}\")\n",
    "    return str(path)\n",
    "\n",
    "def load_model_h5_any(path: str):\n",
    "    import tensorflow as tf\n",
    "    try:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    with h5py.File(path, \"r\") as h5:\n",
    "        blob = bytes(h5[\"pickle\"][()])\n",
    "    return pickle.loads(blob)\n",
    "\n",
    "# --- Plot: Binary\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "def show_cm_and_valacc(model_name, y_true, y_prob, threshold=0.5, savepath=None):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    cm  = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
    "\n",
    "    im = axes[0].imshow(cm, cmap=\"Blues\")\n",
    "    for (i,j),v in np.ndenumerate(cm):\n",
    "        axes[0].text(j, i, str(v), ha=\"center\", va=\"center\", fontsize=10)\n",
    "    axes[0].set_xticks([0,1]); axes[0].set_xticklabels([\"Benign\",\"DDoS\"])\n",
    "    axes[0].set_yticks([0,1]); axes[0].set_yticklabels([\"Benign\",\"DDoS\"])\n",
    "    axes[0].set_xlabel(\"Predicted\"); axes[0].set_ylabel(\"Actual\")\n",
    "    axes[0].set_title(f\"{model_name} — Confusion Matrix\")\n",
    "    fig.colorbar(im, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "    axes[1].bar([0], [acc], width=0.5)\n",
    "    axes[1].set_ylim(0, 1.0)\n",
    "    axes[1].set_xticks([0]); axes[1].set_xticklabels([\"Accuracy\"])\n",
    "    axes[1].set_ylabel(\"Value\")\n",
    "    axes[1].set_title(f\"{model_name} — Validation Accuracy\")\n",
    "    axes[1].text(0, min(acc+0.03, 0.98), f\"{acc:.6f}\", ha=\"center\", va=\"center\", fontsize=11, fontweight=\"bold\")\n",
    "\n",
    "    plt.suptitle(f\"{model_name}  |  ACC={acc:.6f}  AUC={auc:.6f}  thr={threshold}\", y=1.04, fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    if savepath: plt.savefig(savepath, dpi=140, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# --- Plot: Multiclass\n",
    "def show_cm_and_valacc_multiclass(model_name, y_true, y_pred, labels, savepath=None):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(len(labels)))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    im = axes[0].imshow(cm_norm, cmap=\"Blues\", vmin=0, vmax=1)\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        axes[0].text(j, i, str(v), ha=\"center\", va=\"center\", fontsize=8,\n",
    "                     color=\"white\" if cm_norm[i, j] > 0.5 else \"black\")\n",
    "    axes[0].set_xticks(np.arange(len(labels))); axes[0].set_xticklabels(labels, rotation=90)\n",
    "    axes[0].set_yticks(np.arange(len(labels))); axes[0].set_yticklabels(labels)\n",
    "    axes[0].set_xlabel(\"Predicted\"); axes[0].set_ylabel(\"Actual\")\n",
    "    axes[0].set_title(f\"{model_name} — Confusion Matrix (Normalized)\")\n",
    "    fig.colorbar(im, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "\n",
    "    axes[1].bar([0], [acc], width=0.5)\n",
    "    axes[1].set_ylim(0, 1.0)\n",
    "    axes[1].set_xticks([0]); axes[1].set_xticklabels([\"Accuracy\"])\n",
    "    axes[1].set_ylabel(\"Value\")\n",
    "    axes[1].set_title(f\"{model_name} — Validation Accuracy\")\n",
    "    axes[1].text(0, min(acc+0.03, 0.98), f\"{acc:.4f}\", ha=\"center\", va=\"center\", fontsize=11, fontweight=\"bold\")\n",
    "\n",
    "    plt.suptitle(f\"{model_name}  |  ACC={acc:.4f}\", y=1.03, fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    if savepath:\n",
    "        plt.savefig(savepath, dpi=150, bbox_inches=\"tight\")\n",
    "        print(f\"[Saved] {savepath}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7d03c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== EarlyStop theo \"cải thiện quá nhỏ\" giữa 2 epoch liên tiếp (Keras) =====\n",
    "from tensorflow.keras import layers, models, callbacks  # type: ignore\n",
    "\n",
    "class StopOnTinyChange(callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Dừng sớm nếu metric theo dõi (monitor) cải thiện quá nhỏ giữa 2 epoch liên tiếp.\n",
    "    - monitor: 'val_auc' cho bài toán binary, hoặc 'val_accuracy' cho multiclass.\n",
    "    - min_delta: ngưỡng cải thiện tối thiểu. Nếu |Δ| < min_delta => dừng.\n",
    "    \"\"\"\n",
    "    def __init__(self, monitor=\"val_auc\", min_delta=1e-4):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.min_delta = float(min_delta)\n",
    "        self.prev = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        curr = logs.get(self.monitor)\n",
    "        if curr is None:\n",
    "            return\n",
    "        if self.prev is not None and abs(curr - self.prev) < self.min_delta:\n",
    "            print(f\"\\n[STOP] Δ{self.monitor}={curr - self.prev:.6f} < {self.min_delta} tại epoch {epoch+1}. Kết thúc huấn luyện.\")\n",
    "            self.model.stop_training = True\n",
    "        self.prev = curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46eea880",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_BIN = []  # lưu so sánh phase-1\n",
    "\n",
    "def eval_binary(y_true, y_prob, name, threshold=0.5):\n",
    "    y_pred = (y_prob >= threshold).astype(int)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    RESULTS_BIN.append({\"Model\": name, \"ACC\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"AUC\": auc})\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"Benign\",\"DDoS\"]))\n",
    "    print(\"ROC-AUC:\", auc)\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a880750",
   "metadata": {},
   "source": [
    "\n",
    "# **Phase 1: Kết hợp (Ensemble Weighted Soft Voting) giữa XGBoost + LightGBM + LSTM.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035ec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Epoch 1/3 — best_iter: 542\n"
     ]
    }
   ],
   "source": [
    "# %% Phase-1 BEST — Ensemble XGB + LGBM + LSTM SOTA (opt weights, min recall=0.85)\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, accuracy_score\n",
    "\n",
    "cand = []\n",
    "if 'yprob_xgb' in globals():         cand.append(('XGB',  yprob_xgb))\n",
    "if 'yprob_lgb' in globals():         cand.append(('LGBM', yprob_lgb))\n",
    "if 'yprob_lstm_sota' in globals():   cand.append(('LSTM', yprob_lstm_sota)) # type: ignore\n",
    "assert len(cand)>=1, \"Thiếu yprob_* để ensemble.\"\n",
    "\n",
    "names, probs = zip(*cand)\n",
    "P = np.vstack(probs); y = y_test\n",
    "\n",
    "def best_thr(y_true, y_prob, min_rec=0.85):\n",
    "    p, r, thr = precision_recall_curve(y_true, y_prob)\n",
    "    f1 = 2*p[:-1]*r[:-1]/(p[:-1]+r[:-1]+1e-9)\n",
    "    mask = r[:-1] >= min_rec\n",
    "    idx = (np.flatnonzero(mask)[f1[mask].argmax()] if mask.any() else f1.argmax())\n",
    "    return float(thr[idx]), float(p[idx]), float(r[idx]), float(f1[idx])\n",
    "\n",
    "def score(w):\n",
    "    w = np.asarray(w)/(np.sum(w)+1e-12)\n",
    "    yprob = np.dot(w, P)\n",
    "    thr, bp, br, bf1 = best_thr(y, yprob, 0.85)\n",
    "    return dict(w=w, thr=thr, P=bp, R=br, F1=bf1, AUC=roc_auc_score(y,yprob),\n",
    "                ACC=accuracy_score(y,(yprob>=thr).astype(int)))\n",
    "\n",
    "grid = np.arange(0,1.1,0.1); best=None\n",
    "for w in np.array(np.meshgrid(*([grid]*len(names)))).T.reshape(-1,len(names)):\n",
    "    if w.sum()<=0: continue\n",
    "    res = score(w)\n",
    "    if (best is None) or (res['F1']>best['F1']) or (res['F1']==best['F1'] and res['AUC']>best['AUC']):\n",
    "        best = res\n",
    "\n",
    "print(f\"[Ensemble-Binary] {names} -> weights={dict(zip(names, np.round(best['w'],3)))} | thr={best['thr']:.4f}\")\n",
    "print(f\"   P={best['P']:.3f} R={best['R']:.3f} F1={best['F1']:.3f} AUC={best['AUC']:.4f} ACC={best['ACC']:.4f}\")\n",
    "\n",
    "if 'RESULTS_BIN' not in globals(): RESULTS_BIN = []\n",
    "RESULTS_BIN.append({\"Model\": f\"Ensemble[{'+'.join(names)}] (thr@{best['thr']:.3f})\",\n",
    "                    \"ACC\": best['ACC'], \"Precision\": best['P'], \"Recall\": best['R'],\n",
    "                    \"F1\": best['F1'], \"AUC\": best['AUC']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b342222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Phase-1 BEST — Ensemble INLINE Validation (ROC/PR + CM + Report, no saving)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score, precision_recall_curve, average_precision_score,\n",
    "    confusion_matrix, classification_report, accuracy_score, f1_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "\n",
    "# --- helper: best threshold theo F1 (có ràng buộc recall nếu muốn)\n",
    "def _best_thr(y_true, y_prob, min_rec=0.85):\n",
    "    p, r, thr = precision_recall_curve(y_true, y_prob)\n",
    "    f1s = 2*p[:-1]*r[:-1] / np.maximum(p[:-1] + r[:-1], 1e-12)\n",
    "    mask = r[:-1] >= min_rec\n",
    "    idx = (np.flatnonzero(mask)[f1s[mask].argmax()] if mask.any() else int(np.nanargmax(f1s)))\n",
    "    return float(thr[idx]), float(p[idx]), float(r[idx]), float(f1s[idx])\n",
    "\n",
    "def _show_confusion(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 4.0), dpi=140)\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        ax.text(j, i, f\"{v}\", ha='center', va='center')\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout(); plt.show()\n",
    "    return cm\n",
    "\n",
    "# --- dùng kết quả 'best' & 'P' & 'names' từ cell trước\n",
    "w_best = np.asarray(best[\"w\"]) / (np.sum(best[\"w\"]) + 1e-12)\n",
    "yprob_ensemble = np.dot(w_best, P)  # lưu lại để dùng sau nếu cần\n",
    "\n",
    "# --- ROC ---\n",
    "fpr, tpr, _ = roc_curve(y, yprob_ensemble)\n",
    "auc = roc_auc_score(y, yprob_ensemble)\n",
    "plt.figure(figsize=(4.8, 4.0), dpi=140)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.4f}\")\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.title(f\"ROC — Ensemble[{'+'.join(names)}]\")\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- PR ---\n",
    "prec, rec, _ = precision_recall_curve(y, yprob_ensemble)\n",
    "ap = average_precision_score(y, yprob_ensemble)\n",
    "plt.figure(figsize=(4.8, 4.0), dpi=140)\n",
    "plt.plot(rec, prec, label=f\"AP = {ap:.4f}\")\n",
    "plt.title(f\"Precision–Recall — Ensemble[{'+'.join(names)}]\")\n",
    "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.legend(loc=\"lower left\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- đánh giá tại 2 ngưỡng: 0.5 và best-threshold (theo min recall=0.85)\n",
    "thr_best, p_best, r_best, f1_best = _best_thr(y, yprob_ensemble, min_rec=0.85)\n",
    "for th, tag in [(0.5, \"0.50\"), (thr_best, f\"F1*={thr_best:.4f}\")]:\n",
    "    ypred = (yprob_ensemble >= th).astype(int)\n",
    "    acc = accuracy_score(y, ypred)\n",
    "    f1  = f1_score(y, ypred)\n",
    "    ppv = precision_score(y, ypred, zero_division=0)\n",
    "    rr  = recall_score(y, ypred)\n",
    "\n",
    "    print(f\"\\n=== Ensemble[{'+'.join(names)}] @ th={tag} ===\")\n",
    "    print(f\"ACC={acc:.6f} | F1={f1:.6f} | P={ppv:.6f} | R={rr:.6f} | AUC={auc:.6f} | AP={ap:.6f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y, ypred, digits=4))\n",
    "    _ = _show_confusion(y, ypred, f\"Ensemble — Confusion (th={tag})\")\n",
    "\n",
    "# --- In lại thông tin trọng số tối ưu (từ cell trước) cho rõ ràng\n",
    "print(\"\\n[Weights] \" + \", \".join([f\"{n}={w:.3f}\" for n, w in zip(names, w_best)]))\n",
    "print(f\"[Best-threshold] th={thr_best:.6f} | P={p_best:.6f} | R={r_best:.6f} | F1={f1_best:.6f}\")\n",
    "\n",
    "# --- Cập nhật RESULTS_BIN (ghi dòng ensemble với threshold tối ưu)\n",
    "if 'RESULTS_BIN' not in globals():\n",
    "    RESULTS_BIN = []\n",
    "RESULTS_BIN.append({\n",
    "    \"Model\": f\"Ensemble[{'+'.join(names)}] (thr@{thr_best:.3f})\",\n",
    "    \"ACC\": accuracy_score(y, (yprob_ensemble>=thr_best).astype(int)),\n",
    "    \"Precision\": p_best,\n",
    "    \"Recall\": r_best,\n",
    "    \"F1\": f1_best,\n",
    "    \"AUC\": auc\n",
    "})\n",
    "\n",
    "# (tuỳ chọn) hiển thị bảng kết quả tổng hợp nhanh nếu đã có các model trước đó\n",
    "try:\n",
    "    import pandas as pd\n",
    "    df_res = pd.DataFrame(RESULTS_BIN)\n",
    "    display(df_res.sort_values([\"F1\",\"AUC\"], ascending=[False, False]).reset_index(drop=True))\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81be7f",
   "metadata": {},
   "source": [
    "\n",
    "# **Phase 2: Chuẩn bị dữ liệu đa lớp (AttackType)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy tất cả mẫu DDoS\n",
    "df_attack = df_all[df_all['Label']=='DDoS'].copy()\n",
    "X_attack = df_attack.reindex(columns=feature_candidates, fill_value=0.0).astype(np.float32)\n",
    "X_attack_s = scaler.transform(X_attack)\n",
    "\n",
    "# Mã hoá nhãn AttackType\n",
    "y_attack_txt = df_attack['AttackType'].astype(str).values\n",
    "le_attack = LabelEncoder()\n",
    "y_attack = le_attack.fit_transform(y_attack_txt)\n",
    "num_classes = len(le_attack.classes_)\n",
    "joblib.dump(le_attack, ROOT_SAVE / \"attack_label_encoder_union.pkl\")\n",
    "print(\"Classes:\", list(le_attack.classes_))\n",
    "\n",
    "# SMOTE multiclass\n",
    "X_attack_res, y_attack_res = SMOTE(random_state=RANDOM_STATE).fit_resample(X_attack_s, y_attack)\n",
    "\n",
    "# Train/test split\n",
    "Xa_tr, Xa_te, ya_tr, ya_te = train_test_split(\n",
    "    X_attack_res, y_attack_res, test_size=0.2, random_state=RANDOM_STATE, stratify=y_attack_res\n",
    ")\n",
    "Xa_tr = Xa_tr.astype(np.float16)\n",
    "Xa_te = Xa_te.astype(np.float16)\n",
    "print(\"Train:\", Xa_tr.shape, \"Test:\", Xa_te.shape)\n",
    "\n",
    "# Lưu để DL Phase-2 dùng\n",
    "Xa_tr_dl = Xa_tr.astype(np.float32).reshape(-1, Xa_tr.shape[1], 1)\n",
    "Xa_te_dl = Xa_te.astype(np.float32).reshape(-1, Xa_te.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31282d",
   "metadata": {},
   "source": [
    "# **Phase 2 - Hybrid Weighted Soft-Voting Ensemble giữa XGBoost (tree model) và LSTM SOTA (deep learning model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9bf741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Phase-2 BEST — Soft-vote XGB + LSTM SOTA (self-healing)\n",
    "import os, glob, joblib, numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# -------- 0) Ensure Phase-2 data exists (Xa_tr, Xa_te, ya_tr, ya_te, Xa_te_dl) --------\n",
    "need_build = False\n",
    "for v in [\"Xa_tr\",\"Xa_te\",\"ya_tr\",\"ya_te\"]:\n",
    "    if v not in globals():\n",
    "        need_build = True\n",
    "        break\n",
    "\n",
    "if need_build:\n",
    "    print(\"[INFO] Rebuild Phase-2 data from df_all ...\")\n",
    "    # yêu cầu các biến nền tảng: df_all, scaler, feature_candidates, RANDOM_STATE\n",
    "    assert 'df_all' in globals() and 'scaler' in globals() and 'feature_candidates' in globals(), \\\n",
    "        \"Thiếu df_all/scaler/feature_candidates. Hãy chạy các cell chuẩn bị dữ liệu trước.\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from imblearn.over_sampling import SMOTE  # dùng nếu bạn muốn; có thể bỏ để nhanh\n",
    "\n",
    "    # lấy mẫu DDoS + encode AttackType\n",
    "    df_attack = df_all[df_all[\"Label\"]==\"DDoS\"].copy()\n",
    "    X_attack = df_attack.reindex(columns=feature_candidates, fill_value=0.0).astype(np.float32).values\n",
    "    X_attack_s = scaler.transform(X_attack)\n",
    "    y_attack_txt = df_attack[\"AttackType\"].astype(str).values\n",
    "\n",
    "    if 'le_attack' not in globals():\n",
    "        le_attack = LabelEncoder()\n",
    "        y_attack = le_attack.fit_transform(y_attack_txt)\n",
    "    else:\n",
    "        # dùng encoder đang có (nếu đã tồn tại)\n",
    "        y_attack = le_attack.transform(y_attack_txt)\n",
    "\n",
    "    # KHÔNG SMOTE để nhanh (nếu muốn SMOTE hãy bật 2 dòng sau)\n",
    "    # X_attack_res, y_attack_res = SMOTE(random_state=RANDOM_STATE).fit_resample(X_attack_s, y_attack)\n",
    "    # Xa_tr, Xa_te, ya_tr, ya_te = train_test_split(X_attack_res, y_attack_res, test_size=0.2, random_state=RANDOM_STATE, stratify=y_attack_res)\n",
    "    Xa_tr, Xa_te, ya_tr, ya_te = train_test_split(\n",
    "        X_attack_s, y_attack, test_size=0.2, random_state=RANDOM_STATE, stratify=y_attack\n",
    "    )\n",
    "\n",
    "    # DL view để dùng cho LSTM SOTA Multiclass\n",
    "    Xa_tr_dl = Xa_tr.astype(np.float32).reshape(-1, Xa_tr.shape[1], 1)\n",
    "    Xa_te_dl = Xa_te.astype(np.float32).reshape(-1, Xa_te.shape[1], 1)\n",
    "\n",
    "# -------- 1) Ensure xgb_multi exists: load saved pack or (re)train fast --------\n",
    "if 'xgb_multi' not in globals():\n",
    "    print(\"[INFO] xgb_multi not in RAM -> try load saved joblib ...\")\n",
    "    # ưu tiên thư mục results; nếu không có thì tìm local\n",
    "    cand = []\n",
    "    for pat in [\n",
    "        r\"D:\\DACN\\results\\training\\models\\xgb_attack_union.h5\",\n",
    "        r\"D:\\DACN\\results\\training\\models\\*.h5\",\n",
    "        \"xgb_attack_union.joblib\",\n",
    "        \"*.h5\",\n",
    "    ]:\n",
    "        cand.extend(glob.glob(pat))\n",
    "    cand = [p for p in cand if os.path.isfile(p)]\n",
    "    cand = sorted(cand, key=os.path.getmtime, reverse=True)\n",
    "\n",
    "    loaded = False\n",
    "    for p in cand:\n",
    "        try:\n",
    "            pack = joblib.load(p)\n",
    "            if isinstance(pack, dict) and \"model\" in pack:\n",
    "                xgb_multi = pack[\"model\"]\n",
    "                # đồng bộ hoá metadata nếu cần\n",
    "                if \"encoder\" in pack and 'le_attack' not in globals(): le_attack = pack[\"encoder\"]\n",
    "                if \"scaler\" in pack and 'scaler' not in globals():     scaler = pack[\"scaler\"]\n",
    "                if \"features\" in pack and 'feature_candidates' not in globals(): feature_candidates = pack[\"features\"]\n",
    "                print(f\"[OK] Loaded XGB multiclass from: {p}\")\n",
    "                loaded = True\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed to load {p}: {e}\")\n",
    "\n",
    "    if not loaded:\n",
    "        print(\"[INFO] No saved pack -> quick train XGB multiclass (hist, sample_weight)\")\n",
    "        # weight ngược tần suất lớp (nhanh & thường tốt hơn SMOTE)\n",
    "        unique, counts = np.unique(ya_tr, return_counts=True)\n",
    "        inv = counts.max() / counts\n",
    "        w_tr = inv[ya_tr]\n",
    "\n",
    "        xgb_multi = XGBClassifier(\n",
    "            objective=\"multi:softprob\", num_class=len(unique),\n",
    "            n_estimators=500, max_depth=7, learning_rate=0.05,\n",
    "            subsample=0.9, colsample_bytree=0.9,\n",
    "            tree_method=\"hist\", max_bin=256,\n",
    "            random_state=RANDOM_STATE, eval_metric=\"mlogloss\"\n",
    "        )\n",
    "        xgb_multi.fit(Xa_tr, ya_tr, sample_weight=w_tr, eval_set=[(Xa_te, ya_te)], verbose=False)\n",
    "\n",
    "proba_xgb = xgb_multi.predict_proba(Xa_te)  # (n, C)\n",
    "\n",
    "# -------- 2) Optional: DL proba from LSTM SOTA multiclass --------\n",
    "proba_dl = None\n",
    "if 'lstm_sota_mc' in globals():\n",
    "    try:\n",
    "        proba_dl = lstm_sota_mc.predict(Xa_te_dl, batch_size=512, verbose=0)  # type: ignore # (n, C)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] LSTM SOTA multiclass predict failed: {e}\")\n",
    "        proba_dl = None\n",
    "\n",
    "# -------- 3) Soft-vote or fallback --------\n",
    "if proba_dl is None:\n",
    "    y_pred_best = proba_xgb.argmax(axis=1)\n",
    "    name = \"XGBoost (Multiclass)\"\n",
    "else:\n",
    "    w_xgb, w_dl = 0.6, 0.4  # bạn có thể thử 0.7/0.3\n",
    "    y_pred_best = (w_xgb*proba_xgb + w_dl*proba_dl).argmax(axis=1)\n",
    "    name = \"Ensemble[XGB + LSTM SOTA]\"\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "acc = accuracy_score(ya_te, y_pred_best)\n",
    "print(f\"[Phase-2 BEST] {name} — ACC={acc:.4f}\")\n",
    "print(classification_report(ya_te, y_pred_best, target_names=le_attack.classes_))\n",
    "\n",
    "# Alias cho cell tổng hợp Phase-2 cuối\n",
    "y_pred_lstm = y_pred_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7972551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Phase-2 BEST — Multiclass INLINE Validation (CM + Reports + AUC/AP OvR)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, accuracy_score,\n",
    "    f1_score, precision_score, recall_score,\n",
    "    roc_auc_score, average_precision_score, top_k_accuracy_score\n",
    ")\n",
    "import itertools\n",
    "\n",
    "# --- lấy proba đang dùng để suy ra nhãn (từ cell trước)\n",
    "if 'proba_dl' in globals() and proba_dl is not None:\n",
    "    w_xgb, w_dl = 0.6, 0.4  # phải khớp với cell trước\n",
    "    yproba_mc = w_xgb * proba_xgb + w_dl * proba_dl\n",
    "else:\n",
    "    yproba_mc = proba_xgb\n",
    "\n",
    "classes = list(le_attack.classes_)\n",
    "C = len(classes)\n",
    "\n",
    "# --- helpers ---\n",
    "def _plot_cm(cm, labels, title=\"Confusion Matrix\", normalize=False):\n",
    "    if normalize:\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            cm = cm.astype('float') / np.maximum(cm.sum(axis=1, keepdims=True), 1e-12)\n",
    "    fig, ax = plt.subplots(figsize=(1.2 + 0.5*C, 1.0 + 0.5*C), dpi=140)\n",
    "    im = ax.imshow(cm, interpolation='nearest')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_xticks(range(C)); ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_yticks(range(C)); ax.set_yticklabels(labels)\n",
    "    # annotate\n",
    "    fmt = \".2f\" if normalize else \"d\"\n",
    "    thresh = np.nanmax(cm) / 2.0 if np.isfinite(cm).all() else 0.5\n",
    "    for i, j in itertools.product(range(C), range(C)):\n",
    "        val = cm[i, j]\n",
    "        ax.text(j, i, format(val, fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if np.isfinite(val) and val > thresh else \"black\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- Confusion matrices ---\n",
    "cm_raw = confusion_matrix(ya_te, y_pred_best, labels=range(C))\n",
    "_plot_cm(cm_raw, classes, title=f\"{name} — Confusion Matrix (counts)\", normalize=False)\n",
    "_plot_cm(cm_raw, classes, title=f\"{name} — Confusion Matrix (row-normalized)\", normalize=True)\n",
    "\n",
    "# --- Classification report (per-class) ---\n",
    "print(f\"\\n=== {name} — Classification Report ===\")\n",
    "print(classification_report(ya_te, y_pred_best, target_names=classes, digits=4))\n",
    "\n",
    "# --- Overall metrics (macro/micro/weighted) ---\n",
    "acc  = accuracy_score(ya_te, y_pred_best)\n",
    "f1_macro  = f1_score(ya_te, y_pred_best, average=\"macro\")\n",
    "f1_micro  = f1_score(ya_te, y_pred_best, average=\"micro\")\n",
    "f1_weight = f1_score(ya_te, y_pred_best, average=\"weighted\")\n",
    "p_macro   = precision_score(ya_te, y_pred_best, average=\"macro\", zero_division=0)\n",
    "r_macro   = recall_score(ya_te, y_pred_best, average=\"macro\", zero_division=0)\n",
    "\n",
    "# --- AUC (OvR) & Average Precision (OvR) nếu có xác suất ---\n",
    "try:\n",
    "    auc_ovr_macro = roc_auc_score(ya_te, yproba_mc, multi_class=\"ovr\", average=\"macro\")\n",
    "    auc_ovr_weight = roc_auc_score(ya_te, yproba_mc, multi_class=\"ovr\", average=\"weighted\")\n",
    "except Exception:\n",
    "    auc_ovr_macro = np.nan\n",
    "    auc_ovr_weight = np.nan\n",
    "\n",
    "try:\n",
    "    ap_macro = average_precision_score(ya_te, yproba_mc, average=\"macro\")\n",
    "    ap_micro = average_precision_score(ya_te, yproba_mc, average=\"micro\")\n",
    "    ap_weight = average_precision_score(ya_te, yproba_mc, average=\"weighted\")\n",
    "except Exception:\n",
    "    ap_macro = ap_micro = ap_weight = np.nan\n",
    "\n",
    "# --- Top-k accuracy (nếu có proba) ---\n",
    "try:\n",
    "    top2 = top_k_accuracy_score(ya_te, yproba_mc, k=2, labels=range(C))\n",
    "    top3 = top_k_accuracy_score(ya_te, yproba_mc, k=min(3, C), labels=range(C))\n",
    "except Exception:\n",
    "    top2 = top3 = np.nan\n",
    "\n",
    "print(f\"\\n=== {name} — Summary Metrics ===\")\n",
    "print(f\"ACC={acc:.6f} | F1(macro)={f1_macro:.6f} | F1(micro)={f1_micro:.6f} | F1(weighted)={f1_weight:.6f}\")\n",
    "print(f\"P(macro)={p_macro:.6f} | R(macro)={r_macro:.6f}\")\n",
    "print(f\"AUC OvR(macro)={auc_ovr_macro:.6f} | AUC OvR(weighted)={auc_ovr_weight:.6f}\")\n",
    "print(f\"AP(macro)={ap_macro:.6f} | AP(micro)={ap_micro:.6f} | AP(weighted)={ap_weight:.6f}\")\n",
    "print(f\"Top-2 Acc={top2:.6f} | Top-3 Acc={top3:.6f}\")\n",
    "\n",
    "# --- (tuỳ chọn) đẩy nhanh tổng hợp kết quả Phase-2 vào bảng RESULTS_MC ---\n",
    "try:\n",
    "    import pandas as pd\n",
    "    if 'RESULTS_MC' not in globals():\n",
    "        RESULTS_MC = []\n",
    "    RESULTS_MC.append({\n",
    "        \"Model\": name,\n",
    "        \"ACC\": acc,\n",
    "        \"F1_macro\": f1_macro,\n",
    "        \"F1_micro\": f1_micro,\n",
    "        \"AUC_OvR_macro\": auc_ovr_macro,\n",
    "        \"AP_macro\": ap_macro,\n",
    "        \"Top2\": top2\n",
    "    })\n",
    "    df_mc = pd.DataFrame(RESULTS_MC)\n",
    "    display(df_mc.sort_values([\"F1_macro\",\"ACC\"], ascending=[False, False]).reset_index(drop=True))\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb6ad4",
   "metadata": {},
   "source": [
    "# **Dọn Ram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9016ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, sys, types, numpy as np, pandas as pd\n",
    "\n",
    "KEEP = {\n",
    "    # artifacts cần giữ\n",
    "    \"feature_candidates\", \"scaler\", \"le_attack\",\n",
    "    \"xgb_bin\",\"lgb_bin\",\"cat_bin\",\"lstm\",\"gru\",\"cnn\",\"ae\",\n",
    "    \"metrics_phase1\",\"metrics_phase2\",\"best_thresholds\",\n",
    "    # config/seed\n",
    "    \"RANDOM_STATE\",\"split_info\"\n",
    "}\n",
    "\n",
    "SIZE_MB_THRESHOLD = 0  # chỉ dọn biến > 100MB để an toàn\n",
    "\n",
    "def nbytes(obj):\n",
    "    try:\n",
    "        if isinstance(obj, np.ndarray): return obj.nbytes\n",
    "        if isinstance(obj, pd.DataFrame): return obj.memory_usage(deep=True).sum()\n",
    "        if isinstance(obj, pd.Series): return obj.memory_usage(deep=True)\n",
    "        return sys.getsizeof(obj)\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "deleted = []\n",
    "for name, val in list(globals().items()):\n",
    "    if name.startswith(\"_\") or name in KEEP: \n",
    "        continue\n",
    "    if isinstance(val, types.ModuleType) or isinstance(val, types.FunctionType):\n",
    "        continue\n",
    "    try:\n",
    "        mb = nbytes(val) / (1024**2)\n",
    "        if mb >= SIZE_MB_THRESHOLD:\n",
    "            del globals()[name]\n",
    "            deleted.append((name, f\"{mb:.1f} MB\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "gc.collect()\n",
    "print(\"Đã dọn:\", deleted[:10], \"... tổng:\", len(deleted))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
